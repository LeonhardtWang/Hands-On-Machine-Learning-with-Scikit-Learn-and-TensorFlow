{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、对分类器进行投票"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得数据\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)), ('rf', RandomF...,\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))],\n",
       "         flatten_transform=None, n_jobs=1, voting='hard', weights=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "        estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "        voting='hard'\n",
    "    ) # 为hard voting\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.88\n",
      "SVC 0.888\n",
      "VotingClassifier 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LeoWang\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# 观察每个分类器在测试集上的准确率\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)), ('rf', RandomFor...bf',\n",
       "  max_iter=-1, probability=True, random_state=42, shrinking=True,\n",
       "  tol=0.001, verbose=False))],\n",
       "         flatten_transform=None, n_jobs=1, voting='soft', weights=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf = LogisticRegression(random_state=42)\n",
    "rnd_clf = RandomForestClassifier(random_state=42)\n",
    "svm_clf = SVC(probability=True, random_state=42) # 注意这里要设置probability=True\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting='soft') # 为soft voting\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.872\n",
      "SVC 0.888\n",
      "VotingClassifier 0.912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LeoWang\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、Bagging和Pasting  \n",
    "用相同的算法，在训练集不同的随机子集上进行训练，得到每个预测器  \n",
    "Bagging为有放回的，Pasting为无放回的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1 在Scikit-Learn中进行Bagging和Pasting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "        DecisionTreeClassifier(), n_estimators=500,\n",
    "        max_samples=100, bootstrap=True, n_jobs=-1\n",
    "    )\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.912"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2 袋外（OOB）估计**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8986666666666666"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "        DecisionTreeClassifier(), n_estimators=500,\n",
    "        bootstrap=True, n_jobs=-1, oob_score=True)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "bag_clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.904"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.44632768, 0.55367232],\n",
       "       [0.31      , 0.69      ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.1025641 , 0.8974359 ],\n",
       "       [0.36956522, 0.63043478],\n",
       "       [0.01886792, 0.98113208],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96610169, 0.03389831],\n",
       "       [0.76237624, 0.23762376],\n",
       "       [0.01058201, 0.98941799],\n",
       "       [0.73513514, 0.26486486],\n",
       "       [0.87349398, 0.12650602],\n",
       "       [0.96446701, 0.03553299],\n",
       "       [0.06896552, 0.93103448],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98412698, 0.01587302],\n",
       "       [0.93956044, 0.06043956],\n",
       "       [0.98888889, 0.01111111],\n",
       "       [0.00571429, 0.99428571],\n",
       "       [0.41847826, 0.58152174],\n",
       "       [0.9047619 , 0.0952381 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96315789, 0.03684211],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99470899, 0.00529101],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.65921788, 0.34078212],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.16574586, 0.83425414],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.32972973, 0.67027027],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.23      , 0.77      ],\n",
       "       [0.32142857, 0.67857143],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.02339181, 0.97660819],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98984772, 0.01015228],\n",
       "       [0.89265537, 0.10734463],\n",
       "       [0.97883598, 0.02116402],\n",
       "       [0.97340426, 0.02659574],\n",
       "       [0.        , 1.        ],\n",
       "       [0.07070707, 0.92929293],\n",
       "       [0.99465241, 0.00534759],\n",
       "       [0.01183432, 0.98816568],\n",
       "       [0.        , 1.        ],\n",
       "       [0.01219512, 0.98780488],\n",
       "       [0.99447514, 0.00552486],\n",
       "       [0.7902439 , 0.2097561 ],\n",
       "       [0.35164835, 0.64835165],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.68556701, 0.31443299],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.88571429, 0.11428571],\n",
       "       [1.        , 0.        ],\n",
       "       [0.64480874, 0.35519126],\n",
       "       [0.07894737, 0.92105263],\n",
       "       [0.68      , 0.32      ],\n",
       "       [0.89417989, 0.10582011],\n",
       "       [0.        , 1.        ],\n",
       "       [0.13846154, 0.86153846],\n",
       "       [0.86263736, 0.13736264],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.0257732 , 0.9742268 ],\n",
       "       [0.04469274, 0.95530726],\n",
       "       [0.34210526, 0.65789474],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.87564767, 0.12435233],\n",
       "       [0.00588235, 0.99411765],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.22560976, 0.77439024],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.92896175, 0.07103825],\n",
       "       [0.76966292, 0.23033708],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.19230769, 0.80769231],\n",
       "       [0.65745856, 0.34254144],\n",
       "       [0.        , 1.        ],\n",
       "       [0.03664921, 0.96335079],\n",
       "       [0.46703297, 0.53296703],\n",
       "       [1.        , 0.        ],\n",
       "       [0.02222222, 0.97777778],\n",
       "       [0.99418605, 0.00581395],\n",
       "       [0.23076923, 0.76923077],\n",
       "       [0.54010695, 0.45989305],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01675978, 0.98324022],\n",
       "       [0.99456522, 0.00543478],\n",
       "       [0.25142857, 0.74857143],\n",
       "       [0.93      , 0.07      ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.83146067, 0.16853933],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00552486, 0.99447514],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.93434343, 0.06565657],\n",
       "       [0.99431818, 0.00568182],\n",
       "       [0.02197802, 0.97802198],\n",
       "       [0.20903955, 0.79096045],\n",
       "       [0.96610169, 0.03389831],\n",
       "       [0.29411765, 0.70588235],\n",
       "       [0.99450549, 0.00549451],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00546448, 0.99453552],\n",
       "       [0.67525773, 0.32474227],\n",
       "       [0.39267016, 0.60732984],\n",
       "       [0.40740741, 0.59259259],\n",
       "       [0.84831461, 0.15168539],\n",
       "       [0.93413174, 0.06586826],\n",
       "       [0.04123711, 0.95876289],\n",
       "       [0.82285714, 0.17714286],\n",
       "       [0.005     , 0.995     ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02020202, 0.97979798],\n",
       "       [0.98484848, 0.01515152],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00558659, 0.99441341],\n",
       "       [0.        , 1.        ],\n",
       "       [0.0104712 , 0.9895288 ],\n",
       "       [0.00555556, 0.99444444],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.94565217, 0.05434783],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.38942308, 0.61057692],\n",
       "       [0.31284916, 0.68715084],\n",
       "       [0.01036269, 0.98963731],\n",
       "       [0.        , 1.        ],\n",
       "       [0.37078652, 0.62921348],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.97687861, 0.02312139],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.6875    , 0.3125    ],\n",
       "       [0.90810811, 0.09189189],\n",
       "       [0.00515464, 0.99484536],\n",
       "       [0.99470899, 0.00529101],\n",
       "       [0.99441341, 0.00558659],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.08333333, 0.91666667],\n",
       "       [1.        , 0.        ],\n",
       "       [0.02994012, 0.97005988],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02285714, 0.97714286],\n",
       "       [1.        , 0.        ],\n",
       "       [0.89595376, 0.10404624],\n",
       "       [0.72413793, 0.27586207],\n",
       "       [0.56321839, 0.43678161],\n",
       "       [0.        , 1.        ],\n",
       "       [0.15873016, 0.84126984],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96174863, 0.03825137],\n",
       "       [0.96858639, 0.03141361],\n",
       "       [1.        , 0.        ],\n",
       "       [0.0255102 , 0.9744898 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.45      , 0.55      ],\n",
       "       [0.87431694, 0.12568306],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00555556, 0.99444444],\n",
       "       [0.        , 1.        ],\n",
       "       [0.96089385, 0.03910615],\n",
       "       [0.        , 1.        ],\n",
       "       [0.25157233, 0.74842767],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00549451, 0.99450549],\n",
       "       [0.00578035, 0.99421965],\n",
       "       [0.97175141, 0.02824859],\n",
       "       [0.8       , 0.2       ],\n",
       "       [0.99502488, 0.00497512],\n",
       "       [0.00529101, 0.99470899],\n",
       "       [0.1027027 , 0.8972973 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.02083333, 0.97916667],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02453988, 0.97546012],\n",
       "       [1.        , 0.        ],\n",
       "       [0.79679144, 0.20320856],\n",
       "       [0.        , 1.        ],\n",
       "       [0.91      , 0.09      ],\n",
       "       [0.99415205, 0.00584795],\n",
       "       [0.17      , 0.83      ],\n",
       "       [0.19897959, 0.80102041],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00507614, 0.99492386],\n",
       "       [0.        , 1.        ],\n",
       "       [0.24193548, 0.75806452],\n",
       "       [0.95918367, 0.04081633],\n",
       "       [0.00595238, 0.99404762],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99492386, 0.00507614],\n",
       "       [0.        , 1.        ],\n",
       "       [0.48837209, 0.51162791],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01030928, 0.98969072],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.08648649, 0.91351351],\n",
       "       [0.12105263, 0.87894737],\n",
       "       [0.98974359, 0.01025641],\n",
       "       [0.01129944, 0.98870056],\n",
       "       [1.        , 0.        ],\n",
       "       [0.41      , 0.59      ],\n",
       "       [0.11666667, 0.88333333],\n",
       "       [0.51086957, 0.48913043],\n",
       "       [0.61878453, 0.38121547],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.68137255, 0.31862745],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.20430108, 0.79569892],\n",
       "       [0.83050847, 0.16949153],\n",
       "       [0.06779661, 0.93220339],\n",
       "       [1.        , 0.        ],\n",
       "       [0.80808081, 0.19191919],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00534759, 0.99465241],\n",
       "       [0.13690476, 0.86309524],\n",
       "       [0.02762431, 0.97237569],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.9132948 , 0.0867052 ],\n",
       "       [0.17777778, 0.82222222],\n",
       "       [0.96276596, 0.03723404],\n",
       "       [0.03804348, 0.96195652],\n",
       "       [0.58947368, 0.41052632],\n",
       "       [0.07526882, 0.92473118],\n",
       "       [0.99470899, 0.00529101],\n",
       "       [0.79096045, 0.20903955],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.91747573, 0.08252427],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.25806452, 0.74193548],\n",
       "       [0.98882682, 0.01117318],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.85026738, 0.14973262],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.74226804, 0.25773196],\n",
       "       [0.95054945, 0.04945055],\n",
       "       [1.        , 0.        ],\n",
       "       [0.70285714, 0.29714286],\n",
       "       [0.50276243, 0.49723757],\n",
       "       [0.        , 1.        ],\n",
       "       [0.93513514, 0.06486486],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.88324873, 0.11675127],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.72527473, 0.27472527],\n",
       "       [0.10828025, 0.89171975],\n",
       "       [0.43786982, 0.56213018],\n",
       "       [0.30107527, 0.69892473],\n",
       "       [0.        , 1.        ],\n",
       "       [0.88108108, 0.11891892],\n",
       "       [0.80310881, 0.19689119],\n",
       "       [0.00995025, 0.99004975],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.04891304, 0.95108696],\n",
       "       [0.92265193, 0.07734807],\n",
       "       [0.95876289, 0.04123711],\n",
       "       [1.        , 0.        ],\n",
       "       [0.49494949, 0.50505051],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99408284, 0.00591716],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.97969543, 0.02030457],\n",
       "       [0.        , 1.        ],\n",
       "       [0.0255102 , 0.9744898 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01149425, 0.98850575],\n",
       "       [1.        , 0.        ],\n",
       "       [0.11235955, 0.88764045],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.37823834, 0.62176166],\n",
       "       [0.11111111, 0.88888889],\n",
       "       [0.21764706, 0.78235294],\n",
       "       [1.        , 0.        ],\n",
       "       [0.98947368, 0.01052632],\n",
       "       [0.21264368, 0.78735632],\n",
       "       [0.98876404, 0.01123596],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.9516129 , 0.0483871 ],\n",
       "       [0.31155779, 0.68844221],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99492386, 0.00507614],\n",
       "       [0.        , 1.        ],\n",
       "       [0.04395604, 0.95604396],\n",
       "       [0.98395722, 0.01604278],\n",
       "       [1.        , 0.        ],\n",
       "       [0.04278075, 0.95721925],\n",
       "       [0.60119048, 0.39880952]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.oob_decision_function_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、随机贴片和随机子空间  \n",
    "随机贴片：同时对训练样本数和特征进行取样  \n",
    "随机子空间：保留所有的训练样本，对特征进行取样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rnd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.912"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下面这个BaggingClassifier粗略等同于上面的RandomForestClassifier\n",
    "bag_clf = BaggingClassifier(\n",
    "        DecisionTreeClassifier(splitter=\"random\", max_leaf_nodes=16),\n",
    "        n_estimators=500, max_samples=1.0, bootstrap=True, n_jobs=-1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1 Extra-Trees**  \n",
    "对每个特征用随机的阈值，而不是去找到最好可能的阈值  \n",
    "在Scikit-Learn中，用ExtraTreesClassifier类  \n",
    "对于用哪个，无法判断，通过用交叉验证进行比较（并且用网格搜索进行调参）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2 特征重要性**  \n",
    "越重要的特征可能出现在树的根部，越不重要的特征通常出现在树的叶节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm) 0.09877444398444107\n",
      "sepal width (cm) 0.024364337950547058\n",
      "petal length (cm) 0.42293676241811373\n",
      "petal width (cm) 0.4539244556468977\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, n_jobs=-1)\n",
    "rnd_clf.fit(iris[\"data\"], iris[\"target\"])\n",
    "for name, score in zip(iris[\"feature_names\"], rnd_clf.feature_importances_):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 五、Boosting  \n",
    "Boosting指的是任何能够组合几个弱学习器成强学习器的集成方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.1 AdaBoost**  \n",
    "第一个基分类器（如决策树）被用于训练并在测试集上做预测，然后误分类的训练样本权重增大，更新权重，再训练第二个分类器并做预测，更新权重，以此类推，此过程中每次迭代学习率不断减小一半"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第j个预测器的加权错误率：  \n",
    "$r_{j}=\\frac{\\sum_{i=1,\\hat{y}_{j}^{(i)}\\neq y^{(i)}}^{m}w^{(i)}}{\\sum_{i=1}^{m}w^{(i)}}$  \n",
    "其中，$\\hat{y}_{j}^{(i)}$是第j个预测器对第i个样本的预测值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测器权重：  \n",
    "$\\alpha _{j}=\\eta log\\frac{1-r_{j}}{r_{j}}$  \n",
    "其中，$\\alpha$为预测器权重，$\\eta$为学习速率（通常默认为1）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "权重更新公式：  \n",
    "for i = 1, 2, … , m  \n",
    "$w^{(i)}\\leftarrow \\left\\{\\begin{matrix}\n",
    "w^{(i)} & if\\;\\hat{y}_{j}^{(i)}=y^{(i)}\\\\ \n",
    " w^{(i)}exp(\\alpha _{j})& if\\;\\hat{y}_{j}^{i}\\neq y^{(i)}\n",
    "\\end{matrix}\\right.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost预测：  \n",
    "$\\hat{y}(\\textbf{x})=\\mathop{\\arg\\max}_{k}\\sum_{j=1,\\hat{y}_{j}(\\textbf{x})=k}^{N}\\alpha _{j}$  \n",
    "其中，N为预测器的数目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=0.5, n_estimators=200, random_state=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 基于200个决策树桩训练一个AdaBoost分类器\n",
    "# 一个决策树桩为一个最大深度为1的决策树，即由一个单独的决策节点和加上两个叶节点组成\n",
    "# 决策树桩为AdaBoostClassifier类的默认基础估计器\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "        DecisionTreeClassifier(max_depth=1), n_estimators=200,\n",
    "        algorithm=\"SAMME.R\", learning_rate=0.5\n",
    "    )\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.2 Gradient Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=2, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 首先，在训练集之上拟合一个决策树回归\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg1 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=2, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 现在，在第一个预测器产生的残差基础上训练第二个决策树回归\n",
    "y2 = y - tree_reg1.predict(X)\n",
    "tree_reg2 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg2.fit(X, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=2, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 然后，在第二个预测器产生的残差基础上训练第三个决策树回归\n",
    "y3 = y2 - tree_reg2.predict(X)\n",
    "tree_reg3 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg3.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_new = np.array([[0.8, 0.6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最后，我们可以集成以上三个决策树\n",
    "y_pred = sum(tree.predict(X_new) for tree in (tree_reg1, tree_reg2, tree_reg3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15060283])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=1.0, loss='ls', max_depth=2, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=3, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scikit-Learn实现\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3, learning_rate=1.0)\n",
    "gbrt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=2, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=75, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 用认为指定的树的数目去训练GBRT，通过测量训练的每一步的验证误差，找到树的最优数目\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y)\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=120)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "errors = [mean_squared_error(y_val, y_pred) for y_pred in gbrt.staged_predict(X_val)]\n",
    "bst_n_estimators = np.argmin(errors)\n",
    "\n",
    "gbrt_best = GradientBoostingRegressor(max_depth=2, n_estimators=bst_n_estimators)\n",
    "gbrt_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过设置warm_start=True，这样当调用fit()时保持当前的树数目，允许增量式训练\n",
    "# 下面代码展示：当验证错误连续五次迭代都没有改善，则停止训练\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, warm_start=True)\n",
    "\n",
    "min_val_error =float(\"inf\")\n",
    "error_going_up = 0\n",
    "for n_estimators in range(1, 120):\n",
    "    gbrt.n_estimators = n_estimators\n",
    "    gbrt.fit(X_train, y_train)\n",
    "    y_pred = gbrt.predict(X_val)\n",
    "    val_error = mean_squared_error(y_val, y_pred)\n",
    "    if val_error < min_val_error:\n",
    "        min_val_errror = val_error\n",
    "        error_going_up = 0\n",
    "    else:\n",
    "        error_going_up += 1\n",
    "        if error_going_up == 5:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic Gradient Boosting：对于每棵树，随机地用训练集的一部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 六、Stacking（模型融合）  \n",
    "① 将数据集分成两个子集，第一个子集用于训练在第一层的预测器  \n",
    "② 第一层的预测器用于在第二个子集上做预测  \n",
    "③ 将每个样本得到的三个预测值（若有三个预测器）作为输入特征，目标值保持不变，产生新的训练集  \n",
    "④ 在这新的训练集上训练出blender，因此它是学习去在给定第一层预测值的基础上去预测目标值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
